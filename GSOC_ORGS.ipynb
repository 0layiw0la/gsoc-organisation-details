{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2459ad36",
   "metadata": {},
   "source": [
    "# Script to scrape GSOC 2025 organisations and their technologies\n",
    "**Add (options.add_argument(\"--headless\") if you'd rather run in headless mode)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaed7a5",
   "metadata": {},
   "source": [
    "## Scraping the links to all organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a443d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import chromedriver_autoinstaller  \n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "# List to store extracted href links\n",
    "href_list = []\n",
    "\n",
    "# Automatically install chromedriver and get the path\n",
    "driver_path = chromedriver_autoinstaller.install()\n",
    "\n",
    "# Setting up Chrome options for headless browsing\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument(\"--headless\")  # Run in headless mode \n",
    "ua = UserAgent()\n",
    "options.add_argument(f\"user-agent={ua.random}\")  # Set a random user-agent\n",
    "options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
    "options.add_argument(\"--disable-dev-shm-usage\")  # Avoid memory issues\n",
    "options.add_argument(\"--disable-gpu\")  # Disable GPU hardware acceleration\n",
    "    \n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(driver_path, options=options)\n",
    "wait = WebDriverWait(driver, 10)  # Set explicit wait time\n",
    "\n",
    "# Open the target webpage\n",
    "print(\"Opening Google Summer of Code page...\")\n",
    "driver.get(\"https://summerofcode.withgoogle.com/programs/2025/organizations\")\n",
    "\n",
    "time.sleep(3)  # Allow page to load\n",
    "\n",
    "# Scroll down the page a little to trigger lazy loading if needed\n",
    "for _ in range(1):  # Adjust the range if needed\n",
    "    driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "    time.sleep(1)\n",
    "\n",
    "try:\n",
    "\n",
    "    # Click on the first button (modify selector if necessary)\n",
    "    button = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"mat-button-toggle-6-button\"]')))\n",
    "    button.click()\n",
    "        \n",
    "    # Wait for elements to load and scroll for additional content\n",
    "    time.sleep(2)\n",
    "    for _ in range(10):  # Adjust range to ensure full loading\n",
    "        driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Click the dropdown to select a filter (modify selectors if necessary)\n",
    "    bt2 = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"mat-select-value-3\"]')))\n",
    "    bt2.click()\n",
    "            \n",
    "    bt3 = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"mat-option-7\"]')))\n",
    "    bt3.click()\n",
    "        \n",
    "    time.sleep(1)  # Short wait before extracting data\n",
    "        \n",
    "    # Find all organization list elements\n",
    "    orgs = driver.find_elements(By.TAG_NAME, \"app-org-list\")\n",
    "        \n",
    "    for org in orgs:\n",
    "        try:\n",
    "            # Extract the href attribute from each organization's link\n",
    "            link_element = org.find_element(By.TAG_NAME, \"a\")\n",
    "            href = link_element.get_attribute(\"href\")\n",
    "            href_list.append(href)\n",
    "            print(\"Found:\", href)\n",
    "        except Exception:\n",
    "            print(\"No link found in:\", org.get_attribute(\"outerHTML\"))\n",
    "        \n",
    "    print(\"\\nTotal links found:\", len(href_list))\n",
    "        \n",
    "    # Scroll further down for additional results\n",
    "    for _ in range(10):  # Adjust if needed\n",
    "        driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "    # Click the next page button to load more results\n",
    "    bt4 = wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/app-root/app-layout/mat-sidenav-container/mat-sidenav-content[1]/div/div/main/app-program-organizations/app-orgs-grid/section[2]/div/mat-paginator/div/div/div[2]/button[2]')))\n",
    "    bt4.click()\n",
    "    print('Success: Moved to next page')\n",
    "        \n",
    "    # Scroll back up slightly\n",
    "    driver.execute_script(\"window.scrollBy(0, -500);\")\n",
    "    time.sleep(1)\n",
    "        \n",
    "    # Extract links again from the new set of organizations\n",
    "    orgs2 = driver.find_elements(By.TAG_NAME, \"app-org-list\")\n",
    "    for org in orgs2:\n",
    "        try:\n",
    "            link_element = org.find_element(By.TAG_NAME, \"a\")\n",
    "            href = link_element.get_attribute(\"href\")\n",
    "            href_list.append(href)\n",
    "            print(\"Found:\", href)\n",
    "        except Exception:\n",
    "            print(\"No link found in:\", org.get_attribute(\"outerHTML\"))\n",
    "        \n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)  # Handle exceptions\n",
    "\n",
    "finally:\n",
    "    driver.quit()  # Ensure driver closes properly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cd06546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 185 organisations were found\n"
     ]
    }
   ],
   "source": [
    "print(f\"A total of {len(href_list)} organisations were found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274f9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "def scrape_org_details_selenium(href_list):\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    org_data = {}\n",
    "    count = 0\n",
    "    for url in href_list:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(1)  # Allow time for elements to load\n",
    "\n",
    "            # Extract organization name\n",
    "            name_xpath = \"/html/body/app-root/app-layout/mat-sidenav-container/mat-sidenav-content[1]/div/div/main/app-program-organization/app-org-page-title/app-feature-banner/section/div/div/app-feature-cta/div/div[1]/div[1]/h2/span\"\n",
    "            name = wait.until(EC.presence_of_element_located((By.XPATH, name_xpath))).text.strip()\n",
    "\n",
    "            # Extract technologies\n",
    "            tech_xpath = \"/html/body/app-root/app-layout/mat-sidenav-container/mat-sidenav-content[1]/div/div/main/app-program-organization/app-org-info/section/div[2]/div/div/div[1]/div/app-org-info-details/div/div[1]/div[1]/div[2]\"\n",
    "            technologies = wait.until(EC.presence_of_element_located((By.XPATH, tech_xpath))).text.strip()\n",
    "\n",
    "            org_data[name] = technologies\n",
    "            \n",
    "            \n",
    "            \n",
    "            count = count + 1\n",
    "            if (count%10 == 0):\n",
    "                print(f\"Scraped: {count} of 185\")\n",
    "            elif count == 185:\n",
    "                print(\"Done\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to scrape {url}: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "    return org_data\n",
    "\n",
    "\n",
    "data = scrape_org_details_selenium(href_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63d88456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization</th>\n",
       "      <th>Technologies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LabLua</td>\n",
       "      <td>lua, luarocks, kernel, lunatik, pallene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ScummVM</td>\n",
       "      <td>python, opengl, c++, assembly, php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52Â°North Spatial Information Research GmbH</td>\n",
       "      <td>javascript, android, java, web, services, ogc,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AsyncAPI</td>\n",
       "      <td>javascript, java, go, typescript, RAML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openSUSE Project</td>\n",
       "      <td>python, c/c++, go, ruby, reactjs, javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>OpenELIS Global</td>\n",
       "      <td>postgresql, javascript, java, react, spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>The Rust Foundation</td>\n",
       "      <td>python, rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>FOSSASIA</td>\n",
       "      <td>c, python, javascript, django, android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>The JPF team</td>\n",
       "      <td>android, java, distributed, systems, jvm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>webpack</td>\n",
       "      <td>javascript, typescript, node</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Organization  \\\n",
       "0                                        LabLua   \n",
       "1                                       ScummVM   \n",
       "2    52Â°North Spatial Information Research GmbH   \n",
       "3                                      AsyncAPI   \n",
       "4                              openSUSE Project   \n",
       "..                                          ...   \n",
       "180                             OpenELIS Global   \n",
       "181                         The Rust Foundation   \n",
       "182                                    FOSSASIA   \n",
       "183                                The JPF team   \n",
       "184                                     webpack   \n",
       "\n",
       "                                          Technologies  \n",
       "0              lua, luarocks, kernel, lunatik, pallene  \n",
       "1                   python, opengl, c++, assembly, php  \n",
       "2    javascript, android, java, web, services, ogc,...  \n",
       "3               javascript, java, go, typescript, RAML  \n",
       "4         python, c/c++, go, ruby, reactjs, javascript  \n",
       "..                                                 ...  \n",
       "180        postgresql, javascript, java, react, spring  \n",
       "181                                       python, rust  \n",
       "182             c, python, javascript, django, android  \n",
       "183           android, java, distributed, systems, jvm  \n",
       "184                       javascript, typescript, node  \n",
       "\n",
       "[185 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean technologies in the dictionary\n",
    "for key, value in data.items():\n",
    "    cleaned_tech = \", \".join(value.replace(\",\", \" \").split())  # Remove extra commas/spaces\n",
    "    data[key] = cleaned_tech\n",
    "\n",
    "# Now create the DataFrame\n",
    "gsoc_df = pd.DataFrame(list(data.items()), columns=['Organization', 'Technologies'])\n",
    "\n",
    "\n",
    "gsoc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a078219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowed technologies (normalized)\n",
    "allowed_techs = {\"flask\",\"python\", \"javascript\",\"react\",\"node.js\",'typescript','tailwind','django',\"node\",\" pandas\",\"numpy\",\"api\",\"scikit-learn\",\"scikitlearn\",\"sql\",\"mysql\",\"matplot\",\"seaborn\",\"beautifulsoup\",\"selenium\",\"powerbi\",\"github\",\"git\"}  # At least one must be present\n",
    "\n",
    "# Function to filter organizations where at least one allowed tech exists\n",
    "def at_least_one_filter_organizations(df):\n",
    "    filtered_data = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Normalize and split technologies into a set\n",
    "        techs = {t.strip().lower() for t in row['Technologies'].split(\",\")}\n",
    "        \n",
    "        # Check if there's an intersection between row techs and allowed techs\n",
    "        if allowed_techs & techs:  # At least one common element\n",
    "            filtered_data[row['Organization']] = \", \".join(techs)  # Store as a string\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "# Apply filtering\n",
    "filtered_dict = at_least_one_filter_organizations(gsoc_df)\n",
    "\n",
    "# Display results\n",
    "print(filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (lowercase, no spaces)\n",
    "terms_to_remove = {\"go\",\"c++\",\"rust\",\"spring\",\"shell\",\"linux\",\"swift\"}  \n",
    "terms_to_remove = {t.lower().replace(\" \", \"\") for t in terms_to_remove}\n",
    "\n",
    "# Filter the dictionary\n",
    "filtered_dict = {\n",
    "    k: v for k, v in filtered_dict.items()\n",
    "    if not any(term in v.lower().replace(\" \", \"\") for term in terms_to_remove)\n",
    "}\n",
    "\n",
    "# Display the updated dictionary\n",
    "print(filtered_dict)\n",
    "print(len(filtered_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4de538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean technologies in the dictionary\n",
    "for key, value in filtered_dict.items():\n",
    "    cleaned_tech = \", \".join(value.replace(\",\", \" \").split())  # Remove extra commas/spaces\n",
    "    filtered_dict[key] = cleaned_tech\n",
    "\n",
    "# Now create the DataFrame\n",
    "mgsoc_df = pd.DataFrame(list(filtered_dict.items()), columns=['Organization', 'Technologies'])\n",
    "\n",
    "\n",
    "mgsoc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgsoc_df.to_csv('mgsoc_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
